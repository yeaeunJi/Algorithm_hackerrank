{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신경망학습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNF/gdJi8BEEXYI/Sud9E5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeaeunJi/Algorithm_hackerrank/blob/main/%EC%8B%A0%EA%B2%BD%EB%A7%9D%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTbjj55FkLPp"
      },
      "source": [
        "# 신경망 학습\n",
        "- 학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
        "- 이 챕터에서는 신경망이 학습할 수 있도록 해주는 지표인 '손실함수'가 나옴\n",
        "  - 손실 함수의 최소 결과 값을 만드는 가중치 매개 변수를 찾는 것이 신경망 학습의 목표임\n",
        "  - 손실 함수의 값을 가급적 작게 만드는 기법 중 함수의 기울기를 활용하는 경사법을 배울 것임\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Rbv_hwksYt"
      },
      "source": [
        "## 데이터에서 학습\n",
        "- 신경망의 특징은 데이터를 보고 학습할 수 있다는 것이며, 이를 통해 가중치 매개 변수의 값을 자동으로 결정 가능\n",
        "\n",
        "### 데이터 주도 학습\n",
        "- 알고리즘을 밑바닥부터 설계하는 대신 주어진 데이터를 활용하는 방법 존재\n",
        "  - 그 중 하나로 이미지에서 특징(feature)을 추출하고 그 특징의 패턴을 기계학습으로 기술하는 학습 방법이 있음 \n",
        "    * feature : 입력 데이터(입력 이미지)에서 본질적인 데이터(중요한 데이터)를 정확하게 추출할 수 있도록 설계된 변환기를 의미\n",
        "    - 이미지의 특징은 보통 벡터로 기술.\n",
        "    - 이미지 데이터를 벡터로 변환 후 그 데이터를 가지고 지도 학습 방식의 대표 분류 기번인 SVN, KNN 등으로 학습할 수 있음\n",
        "    - 사람이 생각한 특징을 사람이 설계하고 패턴 학습을 기계가 함\n",
        "  - 신경망(딥러닝)은 이미지를 있는 그대로 학습하고, 이미지에 포함된 중요한 특징까지 기계가 스스로 학습함\n",
        "    - 딥러닝을 종단간 기계학습(end-to-end machine learning, 입력에서 출력을 사람의 개입없이 얻음)라고 부르기도 함\n",
        "    - 이점 : 모든 문제를 같은 맥락에서 해결 가능\n",
        "        예) 개 사진 인식 == 사람 사진 인식 == 손글씨 '5' 인식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbyyCmW1nwGC"
      },
      "source": [
        "### 훈련 데이터와 시험 데이터\n",
        "- 기계 학습에서는 데이터를 훈련 데이터(training data)와 시험 데이터(test data)로 나누어 학습과 실험을 수행하는 것이 일반적\n",
        "  - 훈련 데이터를 통해 최적의 매개변수를 가진 모델을 만들고, 시험 데이터를 사용하여 훈련한 모델을 평가\n",
        "  - 훈련 데이터로만 잘 작동되고 일반화되지 못하는 모델을 의미x\n",
        "\n",
        "    (처음보는 데이터를 통해서도 원하는 목표를 이루어내야함)\n",
        " - 기계 학습에서 과대적합(overfitting)을 피하는 것이 중요한 과제 중 하나임\n",
        " * 과대 적합 : 한 데이터셋에만 너무 잘 맞게 학습되어 다른 새로운 데이터로 제대로 성과를 내지 못하는 경우\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp914LfOqLNX"
      },
      "source": [
        "## 손실 함수(Loss function)\n",
        "- 일반적으로 오차제곱합과 교차 엔트로피 오차를 사용\n",
        "- 신경망 성능의 나쁨을 나타내는 지표 중 하나\n",
        "  - 현재 신경망이 훈련 데이터를 얼마나 잘 처리하지 못했는가를 보여줌\n",
        "  - 손실 함수에 -를 곱하면 '얼마나 좋은가'와 같은 지표로 변신 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnn-x21gq5Vv"
      },
      "source": [
        "### 오차제곱합(sum of squares for error, SSE)\n",
        "- 각 원소의 출력(추정값)과 정답의 차를 제곱한 후 그 총합을 구하는 것\n",
        "- 오차제곱합의 기준으로 오차가 더 작은 것이 정답에 더 가까울 것이라고 판단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfrIWq5hjpMQ",
        "outputId": "8ef4ce16-49b4-4515-f534-511b9c0d2f57"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답 # 숫자 2 원핫인코딩\n",
        "\n",
        "def sum_squares_error(y, t) :\n",
        "  return 0.5*np.sum((y-t)**2)\n",
        "\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNgOqcPKksFe"
      },
      "source": [
        "### 교차 엔트로프 오차(cross entropy error, CEE)\n",
        "- 정답일 때의 출력이 전체 값을 정함\n",
        "- 정답에 해당하는 출력이 커질수록 0에 다가가다가, 출력이 1일 때 0이 됨\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSSv7j3X_ugQ",
        "outputId": "40826363-9060-4c6e-ed5d-60b9eb6ff4de"
      },
      "source": [
        "import numpy as np \n",
        "def cross_entropy_error(y,t) :\n",
        "  delta = 1e-7 # np.log() 함수에 0을 입력할 경우, 마이너스 무한대를 뜻하는 -inf가 되어 계산x\n",
        "  \n",
        "  return -np.sum(t*np.log(y+delta)) \n",
        "\n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답 # 숫자 2 원핫인코딩\n",
        "\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]  #  신경망이 숫자 0 ~ 9까지 추론한 확률. 숫자 2일 확률이 가장 높다고 나옴\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EMvR4ooAuOF"
      },
      "source": [
        "### 미니배치 학습\n",
        "- 훈련 데이터 모두에 대한 손실 함수의 합을 구하는 방법\n",
        "- 평균 손실 함수를 구하여 정규화함으로써 훈련 데이터 개수와 관계없이 언제든 통일된 지표를 얻을 수 있음\n",
        "\n",
        "- 하지만 빅데이터와 같은 경우, 모든 데이터를 대상으로 일일이 손실함수를 계산하는 것은 시간이 많이 소요될 수 있음\n",
        "  - 이럴 경우, 데이터의 일부로 전체의 근사치를 추론하여 사용해볼 수 있음\n",
        "    - 미니배치(mini-batch) : 훈련 데이터로부터 무작위로 일부만 골라 학습 수행\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUGL4aWgCayH",
        "outputId": "167f5beb-4090-4dfd-b194-a6df383c492c"
      },
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "__file__ = os.pardir\n",
        "# print(__file__)\n",
        "dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNIST 데이터셋 읽기\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
        "    one_hot_label : \n",
        "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
        "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
        "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     init_mnist()\n",
        "\n",
        "# MNIST 데이터셋을 내려받아 그 이미지를 넘파이 배열로 변화해주는 파이썬 스크립트 사용\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "# from dataset.mnist import load_mnist\n",
        "# load_mnist()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading train-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n",
            "(60000, 784)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cJokLnWAKP2",
        "outputId": "bdc44eba-bd6a-466a-c362-21c80ce9bfde"
      },
      "source": [
        "# 훈련 데이터에서 지정한 수의 데이터를 무작위로 추출하는 코드 구현\n",
        "# 무작위로 10장만 \n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size) # 지정한 범위의 수중 무작위로 원하는 개수만 꺼냄 # 추출할 데이터의 인덱스로 사용\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]\n",
        "\n",
        "print(batch_mask)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[16323  1790 29252 42980 37943 48245 13256 29344 48634 46799]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzSCqtNXC8dp"
      },
      "source": [
        "# 무작위 추출된 인덱스로 미니배치 추출 후 손실함수도 미니 배치로 계산 가능"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si7Ec8qREITi"
      },
      "source": [
        "### (배치용) 교차 엔트로피 오차 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH4xlVvsEFny"
      },
      "source": [
        "# 데이터가 하나일 때와 배치로 묶여 있는 경우 모두 처리할 수 있는 교차 엔트로피 오차 구현\n",
        "def cross_entropy_error(y, t) :\n",
        "  if y.ndim == 1 : # 데이터가 한개\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "  \n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t * np.log(y+1e-7)) / batch_size # 배치 크기로 나누어 정규화하고, 이미지 1장당 평균 교차 엔트로피 오차를 계산"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjBXTGHtxo7X"
      },
      "source": [
        "# 만약 정답 레이블이 원핫인코딩이 아닌 숫자 레이블이라면 다음과 같이 교차 엔트로피 오차를 구현 가능\n",
        "def cross_entropy_error(y, t) :\n",
        "  if y.ndim == 1 :\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "  \n",
        "  batch_size = y.shape[0] # 데이터 수\n",
        "  return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size \n",
        "  # 핵심 : 원핫인코딩일 때 t가 0인 원소는 교차 엔트로피 오차도 0이므로 그 계산 무시해도 좋다\n",
        "  # ===> 정답에 해당하는 신경망의 출력만으로 계산 가능하다는 의미"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG-fTBfzzvTO"
      },
      "source": [
        "### 손실 함수를 설정하는 이유는 무엇인가\n",
        "  - 신경망 학습에서는 최적의 매개변수(가중치와 편향)을 탐색할 대 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는 것이 목표.\n",
        "  - 이때 매개변수의 미분(정확히는 기울기)을 계산하고, 그 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복하여 최적의 매개변수를 찾음\n",
        "  - 어떤 한 신경망의 가중치 매개변수의 손실함수의 미분이란 '가중치 매개변수의 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변화하는가'를 의미함\n",
        "    - 미분 값 < 0 : 가중치 매개변수를 양의 방향으로 변화시켜 손실 함수의 값 감소\n",
        "    - 미분 값 > 0 : 가중치 개매변수를 음의 방향으로 변화시켜 손실 함수의 값 감소\n",
        "    - 미분 값 = 0 : 어느 쪽으로 움직여도 손실 함수의 값은 줄어들지 않으므로 가중치 매개변수의 갱신 중지\n",
        "\n",
        "- 정확도가 아닌 손실 함수의 값을 찾는 이유는 무엇일까?\n",
        "  - 정확도를 지표로 삼을 경우, 매개변수의 미분이 대부분의 장소에서 0이 되어 매개변수 갱신을 할 수 없기 때문\n",
        "    - 예) 한 신경망이 100장의 훈련 데이터 중 32장을 올바르게 인식\n",
        "          정확도 : 32%\n",
        "      \n",
        "      가중치 매개변수의 값을 약간 조정해도 정확도는 바뀌지 않고 일정하게 유지되거나 혹은 연속적인 변화가 아닌 32 --> 33, 34%와 같이 불연속적인 값으로 바뀐다고 함...\n",
        "\n",
        "    - 하지만, 손실 함수를 지표롤 삼을 경우, 매개 변수의 값이 조금 변화하면 그에 반응하여 손실 함수의 값도 연속적으로 변화함\n",
        "\n",
        "  - 계단 함수를 미분할 경우, 대부분의 장소에서 0이되는 것과 비슷\n",
        "  - 즉, 매개변수의 미세한 변화가 일으키는 것을 계단 함수가 말살하여 손실 함수의 값에는 아무런 변화가 나타나지 않음(시그모이드 함수의 기울기는 0이 아님)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KRWyrqn7hNP"
      },
      "source": [
        "## 수치 미분(numerical differentiation)\n",
        "- 경사법에서는 기울기(경사) 값을 기준으로 나아갈 뱡향을 정함\n",
        "- 수치 미분에는 오차가 포함되므로 함수의 차분을 게산하는 방법을 쓰기도 함\n",
        "- 아주 작은 차분으로 미분하는 것(근사치로 계산)\n",
        "\n",
        "- 해석적(analytic) 미분 : 수식을 통해 미분하는 것으로 오차를 포함하지 않는 진정한 미분을 계산(우리가 배운 미분하는 방법)\n",
        "\n",
        "### 미분\n",
        "- '특정 순간'의 변화량(어느 순간의 속도)\n",
        "- x의 작은 변화가 함수 f(x)를 얼마나 변화시키는 가\n",
        " (시간인 h가 한없이 0에 가까워질정도의시간의 작은 변화일 때)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnPIxKtfyzla"
      },
      "source": [
        "# 함수를 미분하는 계산 \n",
        "def numerical_diff(f, x) :\n",
        "  h = 10e-50 # h에 작은 값을 대입해 다음과 같이 계산 가능\n",
        "  return (f(x+h)-f(x)) / h"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppBHun469YsB",
        "outputId": "82ca165d-decb-4a35-baaa-d88c945e75db"
      },
      "source": [
        "# 1. 위에서 정의한 함수는 h를 정의한 방식에서 반올림 오차(rounding error)문제를 일으킴\n",
        "# 반올림 오차 : 작은 값(가령 소수점 8자리 이하)이 생략되어 최종 계산 결과에 오차가 생기게 됨\n",
        "import numpy as np\n",
        "np.float32(1e-50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRsUlJ2D9tLC"
      },
      "source": [
        "# 따라서 좋은 결과를 준다고 알려진 미세한 값인 1e-4 사용\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHTlnZEb95ZV"
      },
      "source": [
        "# 2. 함수 f의 차분(임의 두 점에서의 함수 값들의 차이)\n",
        "# 진정한 의미에서의 미분은 x 위치의 함수의 길울기(접선)에 해당하지만 위에서 구현한 미분은 x+h와 X 사이의 기울기에 해당\n",
        "# 이는 h를 무한히 0으로 좁히는 것이 불가능하여 생긴 문제\n",
        "# 중심차분 혹은 중앙 차분 : x를 중심으로 그 전후의 차분을 계싼 . (x+h)와 (x-h)일 때의 함수 f의 차분을 계산\n",
        "def numerical_diff(f, x) :\n",
        "  h = 1e-4\n",
        "  return (f(x+h)-f(x-h)) / (2*h)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h58QSaNf_WDN"
      },
      "source": [
        "### 수치 미분의 예\n",
        " y = 0.01(x**2) + 0.1x 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te1-A7h1_VKM"
      },
      "source": [
        "def function_1(x) :\n",
        "  return 0.01*x**2 + 0.1*x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "EWJmF_vX_9o9",
        "outputId": "d84133fc-d129-43b9-fdb3-77c39a4375ab"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1) # 0.0에서 20.0까지 0.1 간격으로 배열 x를 만든다(20미포함)\n",
        "y = function_1(x)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.plot(x,y)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEr162ftAIBQ",
        "outputId": "4b24058e-e2f4-483d-9481-a74c9c1e1173"
      },
      "source": [
        "# x = 5일 때와 10일 때 미분\n",
        "print(numerical_diff(function_1, 5)) # x대한 f(x)의 변화량(기울기)\n",
        "print(numerical_diff(function_1, 10))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1999999999990898\n",
            "0.2999999999986347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkz4uyV6AnhQ"
      },
      "source": [
        "### 편미분\n",
        " f(x0, x1) = x0 ** 2 + x1 ** 2\n",
        "\n",
        " - 변수가 여럿인 함수에 대한 미분\n",
        " (x0에 대한 미분이냐 x1에 대한 미분이냐 구별 필요)\n",
        "\n",
        " - 변수가 하나인 미분과 동일하게 특정 장소의 기울기를 구하지만 여러 변수 중 목표 변수 하나만 살리고 나머지는 고정하여 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oydNnixCATgi"
      },
      "source": [
        "def function_2(x) :\n",
        "  return x[0]**2 + x[1]**2\n",
        "  # 또는 return np.sum(x**2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPokovKPBEKk"
      },
      "source": [
        "# 이 식에 대한 그래프는 3차원으로 그려짐"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXf_hz04B2Tf",
        "outputId": "d1e8b8f1-1ee7-4b5e-a6dc-4d018777c91a"
      },
      "source": [
        "# x0=3, x1 =4 일때 x0에 대한 편미분\n",
        "def function_tmp1(x0) :\n",
        "  return x0*x0 + 4.0**2.0\n",
        "\n",
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjLNlDUZCRdE",
        "outputId": "cb2576f7-3fdb-4a35-acbf-9cc01f17865b"
      },
      "source": [
        "# x0=3, x1=4일 때 x1에 대한 편미분\n",
        "def function_tmp2(x1) :\n",
        "  return 0.3**2.0 + x1*x1\n",
        "  \n",
        "numerical_diff(function_tmp2, 4.0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.999999999999119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRvde7fqCum7"
      },
      "source": [
        "## 기울기(gradient)\n",
        "- x0과 x1의 편미분을 동시에 계산하고 싶다면 어떻게 해야할까?\n",
        "- 기울기 :모든 변수의 편미분을 벡터로 정리한 것\n",
        "- 기울기는 각 지점에서 낮아지는 방향을 가리킴(기울기가 가리키는 쪽은 각 장소에서 함수의 출력값을 가장 크게 줄이는 방향)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B08__0PFCgE3"
      },
      "source": [
        "# x0=3, x1=4일 때 각 점에서의 기울기를 구하는 함수 구현\n",
        "def numerical_gradient(f, x) :\n",
        "  h = 1e-4 \n",
        "  grad = np.zeros_like(x) # x와 형상(shape)이 같고 값은 0으로 채워진 배열을 생성\n",
        "\n",
        "  for idx in range(x.size) :\n",
        "    tmp_val = x[idx]\n",
        "    # f(x+h) 계산\n",
        "    x[idx] = tmp_val + h\n",
        "    fxh1 = f(x)\n",
        "\n",
        "    # f(x-h) 계산\n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "\n",
        "    grad[idx] = (fxh1-fxh2) / (2*h)\n",
        "    x[idx] = tmp_val # 값 복원 \n",
        "\n",
        "  return grad"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPTFNEN2EDFy",
        "outputId": "a58ca73a-c80a-4f35-b4a9-9cb29e84f3f7"
      },
      "source": [
        "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
        "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
        "print(numerical_gradient(function_2, np.array([3.0, 0.0])))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6. 8.]\n",
            "[0. 4.]\n",
            "[6. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyOqfaExEQbn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}